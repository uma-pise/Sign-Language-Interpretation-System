# Sign-Language-Interpretation-System
    A Complete Sign Language interpretation system which will be a platform to learn Indian Sign Language as well as to make communication easy between deaf-dumb and normal people.This project proposing a system for transforming voice commands to video, contains Indian sign language using hand gestures as well as for converting video into the audio format.
    In this project, we proposed to build a complete sign language interpretation system which will be a platform to learn Indian Sign Language (ISL). The system is divided into two parts that is conversion of sign video to audio format and conversion of speech to sign video. The system will be useful for normal, deaf and mute people which provide efficient and accurate way to convert sign language to text and audio as well as vice-versa. 
    The models will be based on convert sign language to audio and video to speech. The CNN model will be used to extract frames from the video and to predict hand gestures. It is a multi-layered feed forward neural network mostly used in image recognition. They have applications in image and video recognition, recommender systems, image classification, image segmentation, frame extraction, natural language processing. CNNs are regularized versions of multilayer perceptron.
    In this project GUI used as a platform. Which makes it easier to manage multiple tasks. At one single time users can work and view two or more programs. GUI uses a combination of technologies and devices to provide a platform that users can interact with, for the tasks of gathering and producing information.
